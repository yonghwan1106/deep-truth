"""
ìŒì„± ë¶„ì„ API ë¼ìš°í„°
ë”¥í˜ì´í¬ íƒì§€ + í™”ì ê²€ì¦ í†µí•© ë¶„ì„
HuggingFace Inference API ì—°ë™
"""

from fastapi import APIRouter, UploadFile, File, HTTPException
from pydantic import BaseModel
from typing import List, Optional
import time

from models.deepfake_detector import get_detector
from models.speaker_verifier import get_verifier

router = APIRouter()


class AnalysisResult(BaseModel):
    deepfake_probability: float
    voiceprint_match: float
    matched_person: Optional[str]
    risk_level: str
    recommendations: List[str]
    audio_duration: float
    analysis_time: float
    analysis_mode: str  # 'api' ë˜ëŠ” 'mock'


class QuickAnalysisResult(BaseModel):
    deepfake_probability: float
    is_suspicious: bool
    analysis_mode: str


@router.post("/", response_model=AnalysisResult)
async def analyze_audio(file: UploadFile = File(...)):
    """
    ìŒì„± íŒŒì¼ ë¶„ì„ - ë”¥í˜ì´í¬ íƒì§€ + ì„±ë¬¸ ëŒ€ì¡°

    HuggingFace Inference APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ AI ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    API í† í°ì´ ì—†ëŠ” ê²½ìš° ëª©ì—… ëª¨ë“œë¡œ ë™ì‘í•©ë‹ˆë‹¤.
    """
    # íŒŒì¼ í˜•ì‹ ê²€ì¦
    allowed_types = [
        'audio/mpeg', 'audio/wav', 'audio/x-wav',
        'audio/mp4', 'audio/ogg', 'audio/webm',
        'audio/x-m4a', 'audio/flac'
    ]

    # content_typeì´ Noneì¸ ê²½ìš°ë„ í—ˆìš© (íŒŒì¼ í™•ì¥ìë¡œ íŒë‹¨)
    if file.content_type and file.content_type not in allowed_types:
        # í™•ì¥ì ì²´í¬
        filename = file.filename or ""
        valid_extensions = ['.mp3', '.wav', '.m4a', '.ogg', '.webm', '.flac']
        if not any(filename.lower().endswith(ext) for ext in valid_extensions):
            raise HTTPException(status_code=400, detail="ì§€ì›í•˜ì§€ ì•ŠëŠ” ì˜¤ë””ì˜¤ í˜•ì‹ì…ë‹ˆë‹¤")

    # íŒŒì¼ ì½ê¸°
    start_time = time.time()
    content = await file.read()
    file_size = len(content)

    # AI ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
    detector = get_detector()
    verifier = get_verifier()

    # ë”¥í˜ì´í¬ íƒì§€ (HuggingFace API ë˜ëŠ” ëª©ì—…)
    deepfake_result = await detector.detect(audio_bytes=content)

    # í™”ì ê²€ì¦ (HuggingFace API ë˜ëŠ” ëª©ì—…)
    voiceprint_result = await verifier.verify(audio_bytes=content)

    # ê²°ê³¼ ì¶”ì¶œ
    deepfake_prob = deepfake_result.get("probability", 50.0)
    voiceprint_match = voiceprint_result.get("similarity", 0.0)
    matched_person = voiceprint_result.get("matched_member")

    # ë¶„ì„ ëª¨ë“œ í™•ì¸
    deepfake_mode = deepfake_result.get("status", "mock")
    voiceprint_mode = voiceprint_result.get("mode", "mock")
    analysis_mode = "api" if deepfake_mode == "success" or voiceprint_mode == "api" else "mock"

    # ìœ„í—˜ë„ íŒì •
    if deepfake_prob > 70 or voiceprint_match < 30:
        risk_level = "high"
        recommendations = [
            "âš ï¸ ë³¸ì¸ì—ê²Œ ì˜ìƒí†µí™”ë¡œ ì§ì ‘ í™•ì¸í•˜ì„¸ìš”",
            "ğŸš¨ ê²½ì°°ì²­ 112ì— ì‹ ê³ í•˜ì„¸ìš”",
            "ğŸ’° ì ˆëŒ€ ì†¡ê¸ˆí•˜ì§€ ë§ˆì„¸ìš”"
        ]
    elif deepfake_prob > 40 or voiceprint_match < 60:
        risk_level = "medium"
        recommendations = [
            "ğŸ“ ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤",
            "ğŸ‘¤ ë³¸ì¸ì—ê²Œ ì§ì ‘ ì—°ë½í•˜ì—¬ í™•ì¸í•˜ì„¸ìš”"
        ]
    else:
        risk_level = "low"
        recommendations = [
            "âœ… ì •ìƒì ì¸ ìŒì„±ìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤",
            "ğŸ’¡ ê·¸ë˜ë„ ì˜ì‹¬ë˜ë©´ ì§ì ‘ í™•ì¸í•˜ì„¸ìš”"
        ]

    # ë¶„ì„ ì‹œê°„ ê³„ì‚°
    analysis_time = time.time() - start_time

    return AnalysisResult(
        deepfake_probability=round(deepfake_prob, 1),
        voiceprint_match=round(voiceprint_match, 1),
        matched_person=matched_person,
        risk_level=risk_level,
        recommendations=recommendations,
        audio_duration=round(file_size / 32000, 2),  # ì¶”ì •ê°’ (16kHz, 16bit)
        analysis_time=round(analysis_time, 2),
        analysis_mode=analysis_mode
    )


@router.post("/quick", response_model=QuickAnalysisResult)
async def quick_analysis(file: UploadFile = File(...)):
    """
    ë¹ ë¥¸ ë¶„ì„ - ë”¥í˜ì´í¬ íƒì§€ë§Œ ìˆ˜í–‰

    ì„±ë¬¸ ëŒ€ì¡° ì—†ì´ ë”¥í˜ì´í¬ ì—¬ë¶€ë§Œ ë¹ ë¥´ê²Œ í™•ì¸í•©ë‹ˆë‹¤.
    """
    content = await file.read()

    # AI ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
    detector = get_detector()

    # ë”¥í˜ì´í¬ íƒì§€
    result = await detector.detect(audio_bytes=content)

    deepfake_prob = result.get("probability", 50.0)
    analysis_mode = result.get("status", "mock")

    return QuickAnalysisResult(
        deepfake_probability=round(deepfake_prob, 1),
        is_suspicious=deepfake_prob > 50,
        analysis_mode="api" if analysis_mode == "success" else "mock"
    )


@router.get("/status")
async def get_analysis_status():
    """
    ë¶„ì„ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸

    HuggingFace API ì—°ê²° ìƒíƒœ ë° ëª¨ë“œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    detector = get_detector()
    verifier = get_verifier()

    return {
        "deepfake_detector": {
            "mode": "api" if not detector._prototype_mode else "mock",
            "model": detector.DEEPFAKE_MODEL,
            "is_loaded": detector.is_loaded
        },
        "speaker_verifier": {
            "mode": "api" if not verifier._prototype_mode else "mock",
            "model": verifier.SPEAKER_MODEL,
            "is_loaded": verifier.is_loaded,
            "registered_members": len(verifier.voiceprints)
        }
    }
